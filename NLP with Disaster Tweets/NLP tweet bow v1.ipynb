{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"tw = pd.read_csv('/kaggle/input/nlp-getting-started/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tw_test = pd.read_csv('/kaggle/input/nlp-getting-started/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tw.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tw.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tw.target.value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"EDA on keyword"},{"metadata":{"trusted":true},"cell_type":"code","source":"keyword_list = tw.keyword.unique().tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_rate = []\nfor kw in tw.keyword.unique():\n    target_rate.append(tw[tw.keyword==kw].target.mean())","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"for kw in keyword_list:\n    print(kw,':')\n    print(tw[tw.keyword==kw].target.mean())\n    print('----')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"keyword_df = pd.DataFrame({\n    'keyword':keyword_list[1:],\n    'target_rate':target_rate[1:]\n})\nkeyword_df\nkeyword_df.sort_values(by='target_rate', ascending=False)[:20]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"EDA on location"},{"metadata":{"trusted":true},"cell_type":"code","source":"tw.location.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tw.location.value_counts(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tw[pd.notna(tw.keyword)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Tokenization"},{"metadata":{"trusted":true},"cell_type":"code","source":"tw.text[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# convery tweets to lowercase\ntw['clean_text'] = tw['text'].str.lower()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# remove non-alphanumeric characteristics\nimport re\ntw['clean_text'] = tw['clean_text'].str.replace('\\W+', ' ')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# tokenize\nimport nltk\ntw['clean_text'] = tw['clean_text'].apply(nltk.word_tokenize)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# stem\nfrom nltk.stem.porter import PorterStemmer\n\nstemmer = PorterStemmer()\n\ntw['clean_text'] = tw['clean_text'].apply(lambda x: [stemmer.stem(word) for word in x])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tw.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# use TfidfVectorizer to convert sentences to features. It will also remove stopwords.\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\ntfidf = TfidfVectorizer(stop_words = 'english', use_idf = False, norm = None, binary = True, lowercase = True)\n\nX = tfidf.fit_transform(tw['clean_text'].str.join(' '))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = tw['target']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, f1_score\n\n\nclfrf = RandomForestClassifier(n_estimators = 10)\nclfrf.fit(X_train, y_train)\ny_predrf = clfrf.predict(X_test)\nf1rf = f1_score(y_test, y_predrf, average = \"macro\")\naccuracyrf = accuracy_score(y_test, y_predrf)\nprint(\"Random forest f1 score:\", f1rf, \"accuracy:\", accuracyrf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# feature importance\npd.Series(index=tfidf.get_feature_names(), data=clfrf.feature_importances_).sort_values(ascending=False)[:20]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# gridsearch\n\nfrom sklearn.model_selection import GridSearchCV\n\ngrid_params = [ { 'n_estimators':[100,200] }]\n\nclf = GridSearchCV(RandomForestClassifier(), grid_params, cv = 3, scoring='f1_macro')\nclf.fit(X_train, y_train)\n\nprint(\"Best parameter values: %r\\n\" % clf.best_params_)\nprint(\"Grid scores:\")\nmeans = clf.cv_results_['mean_test_score']\nstds = clf.cv_results_['std_test_score']\nfor mean, std, params in zip(means, stds, clf.cv_results_['params']):\n    print(\"%0.3f, stdev %.3f on %r\" % (mean, std, params))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tw_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tw_test['clean_text'] = tw_test['text'].str.lower()\ntw_test['clean_text'] = tw_test['clean_text'].str.replace('\\W+', ' ')\ntw_test['clean_text'] = tw_test['clean_text'].apply(nltk.word_tokenize)\n\nstemmer = PorterStemmer()\ntw_test['clean_text'] = tw_test['clean_text'].apply(lambda x: [stemmer.stem(word) for word in x])\n\nX_tw_test = tfidf.transform(tw_test['clean_text'].str.join(' '))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tw_test['target'] = clfrf.predict(X_tw_test)\ntw_test = tw_test[['id', 'target']]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tw_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tw_test.to_csv('submission_bow_v1', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}